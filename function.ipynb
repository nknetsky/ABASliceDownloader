{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from allensdk.api.queries.image_download_api import ImageDownloadApi\n",
    "from allensdk.config.manifest import Manifest\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gene_by_id(results_df, ExperimentID):\n",
    "    gene_name = results_df[\"Gene Symbol\"][\n",
    "        results_df[\"ExperimentID\"] == ExperimentID\n",
    "    ].iloc[0]\n",
    "    print(\n",
    "        \"You are requesting for downloading brain lices of \"\n",
    "        + gene_name\n",
    "        + \" (\"\n",
    "        + ExperimentID\n",
    "        + \")\",\n",
    "        file=sys.stderr,\n",
    "        flush=True,\n",
    "    )\n",
    "    print(\n",
    "        'The downloaded brain lices will be placed in the dir \"' + gene_name + '\".',\n",
    "        file=sys.stderr,\n",
    "        flush=True,\n",
    "    )\n",
    "    return gene_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_by_search_gene_name(keywords):\n",
    "\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    for keyword in keywords:\n",
    "\n",
    "        url = \"https://mouse.brain-map.org/search/show?search_term=\" + keyword\n",
    "        driver.get(url)\n",
    "        time.sleep(2)\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "        # Get the search results as dataframe\n",
    "\n",
    "        # store the info of a search\n",
    "        results_df = pd.DataFrame()\n",
    "\n",
    "        # iterate necessary columns\n",
    "        for ii, col in enumerate([1, 2, 3, 6]):\n",
    "\n",
    "            # store the info of a column\n",
    "            results = []\n",
    "\n",
    "            # iterate rows\n",
    "            for row in soup.select(\"div[row]\"):\n",
    "                if col == 1 or col == 2:\n",
    "                    result = (\n",
    "                        row.select(\"div.c\" + str(col))[0]\n",
    "                        .select(\"a\")[0]\n",
    "                        .getText()\n",
    "                        .strip()\n",
    "                    )\n",
    "                else:\n",
    "                    result = row.select(\"div.c\" + str(col))[0].getText().strip()\n",
    "                    \n",
    "                if result:\n",
    "                    \n",
    "                    # store a result (an item) in the results list\n",
    "                    results.append(result)\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            if results:          \n",
    "                # integrate the results list into a results_df\n",
    "                results_df = pd.concat([results_df, pd.Series(results)], axis=1)\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        print(\"Keyword: \" + keyword)\n",
    "\n",
    "        if not results_df.empty:\n",
    "            # create a list of names of columns\n",
    "            header = [\"ExperimentID\", \"Gene Symbol\", \"Gene Name\", \"Plane\"]\n",
    "\n",
    "            # assign the header to the results_df\n",
    "            results_df.columns = header\n",
    "            print(results_df, end=\"\\n\")\n",
    "        else:\n",
    "            print(\"No results.\")\n",
    "\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_brain_slice(exp_id, dirname, path):\n",
    "\n",
    "    # create an image download API\n",
    "    image_api = ImageDownloadApi()\n",
    "\n",
    "    section_data_set_id = int(exp_id)\n",
    "    downsample = 0\n",
    "\n",
    "    section_image_directory = os.path.join(path, dirname)\n",
    "    format_str = \".jpg\"\n",
    "\n",
    "    # get the image ids for all of the images in this data set\n",
    "    section_images = image_api.section_image_query(\n",
    "        section_data_set_id\n",
    "    )  # Should be a dicionary of the features of section images\n",
    "    section_image_ids = [\n",
    "        si[\"id\"] for si in section_images\n",
    "    ]  # Take value of 'id' from the dictionary\n",
    "\n",
    "    print(\n",
    "        \"There are \" + str(len(section_image_ids)) + \" slices.\",\n",
    "        file=sys.stderr,\n",
    "        flush=True,\n",
    "    )\n",
    "\n",
    "    # You have probably noticed that the AllenSDK has a logger which notifies you of file downloads.\n",
    "    # Since we are downloading ~300 images, we don't want to see messages for each one.\n",
    "    # The following line will temporarily disable the download logger.\n",
    "    logging.getLogger(\"allensdk.api.api.retrieve_file_over_http\").disabled = True\n",
    "\n",
    "    print(\n",
    "        \"Downloads initiated\", end=\"...\", file=sys.stderr, flush=True,\n",
    "    )\n",
    "    \n",
    "    # Create a progress bar\n",
    "    pbar = tqdm(total=len(section_image_ids), desc=\"Downloading...\")\n",
    "\n",
    "    for index, section_image_id in enumerate(section_image_ids):\n",
    "\n",
    "        file_name = str(section_image_id) + format_str\n",
    "        file_path = os.path.join(section_image_directory, file_name)\n",
    "\n",
    "        Manifest.safe_make_parent_dirs(file_path)\n",
    "\n",
    "        # Check if the file is already downloaded, which happens if the downloads have been interrupted.\n",
    "        saved_file_names = os.listdir(section_image_directory)\n",
    "        if file_name in saved_file_names:\n",
    "            continue\n",
    "\n",
    "        image_api.download_section_image(\n",
    "            section_image_id, file_path=file_path, downsample=downsample\n",
    "        )\n",
    "        \n",
    "        pbar.update()\n",
    "\n",
    "    pbar.close()\n",
    "    \n",
    "    # re-enable the logger\n",
    "    logging.getLogger(\"allensdk.api.api.retrieve_file_over_http\").disabled = False\n",
    "    print(\n",
    "        \"Downloads completed.\", file=sys.stderr, flush=True,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
